{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7cbe5ee",
   "metadata": {},
   "source": [
    "# Reparameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9725e211",
   "metadata": {},
   "source": [
    "\n",
    "### What is Reparameterization ?\n",
    "Reparameterization is used to reduce trainable BoF modules into deploy model for fast inference. For example merge BN to conv, merge YOLOR to conv, ..etc\n",
    "However, before reparameterization, the model has more parameters and computation cost.reparameterized model (cfg/deploy) used for deployment purpose\n",
    "\n",
    "\n",
    "\n",
    "### Steps required for model conversion.\n",
    "1.train custom model & you will get your own weight i.e custom_weight.pt / use (pretrained weight which is available i.e yolov7_traing.pt)\n",
    "\n",
    "2.Converting this weight using  Reparameterization  method.\n",
    "\n",
    "3.Trained model (cfg/training) and reparameterized model (cfg/deploy) will get same prediction results.\n",
    "However, before reparameterization, the model has more parameters and computation cost.\n",
    "\n",
    "4.Convert reparameterized weight into onnx & tensorrt\n",
    "For faster inference & deployment purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13393b70",
   "metadata": {},
   "source": [
    "## YOLOv7 reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ae980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/yolov7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac54b511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('export.py'),\n",
       " PosixPath('README.md'),\n",
       " PosixPath('data'),\n",
       " PosixPath('figure'),\n",
       " PosixPath('runs'),\n",
       " PosixPath('train.py'),\n",
       " PosixPath('test.py'),\n",
       " PosixPath('detect.py'),\n",
       " PosixPath('inference'),\n",
       " PosixPath('requirements.txt'),\n",
       " PosixPath('deploy'),\n",
       " PosixPath('export'),\n",
       " PosixPath('tensorrt-python'),\n",
       " PosixPath('paper'),\n",
       " PosixPath('utils'),\n",
       " PosixPath('tools'),\n",
       " PosixPath('models'),\n",
       " PosixPath('LICENSE.md'),\n",
       " PosixPath('scripts'),\n",
       " PosixPath('.git'),\n",
       " PosixPath('cfg'),\n",
       " PosixPath('.gitignore'),\n",
       " PosixPath('train_aux.py'),\n",
       " PosixPath('yolov7-tiny.pt'),\n",
       " PosixPath('hubconf.py')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "list(Path().iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf53becf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model.77.im.0.implicit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30511/2822897432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# reparametrized YOLOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.77.m.0.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.77.im.0.implicit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.77.m.1.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.77.im.1.implicit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.77.m.2.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.77.im.2.implicit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model.77.im.0.implicit'"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load('yolov7-tiny.pt', map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "model = Model('cfg/deploy/yolov7-tiny.yaml', ch=3, nc=80).to(device)\n",
    "\n",
    "with open('cfg/deploy/yolov7.yaml') as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'][0]) // 2\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "# reparametrized YOLOR\n",
    "for i in range((model.nc+5)*anchors):\n",
    "    model.state_dict()['model.77.m.0.weight'].data[i, :, :, :] *= state_dict['model.77.im.0.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.77.m.1.weight'].data[i, :, :, :] *= state_dict['model.77.im.1.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.77.m.2.weight'].data[i, :, :, :] *= state_dict['model.77.im.2.implicit'].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.77.m.0.bias'].data += state_dict['model.77.m.0.weight'].mul(state_dict['model.77.ia.0.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.77.m.1.bias'].data += state_dict['model.77.m.1.weight'].mul(state_dict['model.77.ia.1.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.77.m.2.bias'].data += state_dict['model.77.m.2.weight'].mul(state_dict['model.77.ia.2.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.77.m.0.bias'].data *= state_dict['model.77.im.0.implicit'].data.squeeze()\n",
    "model.state_dict()['model.77.m.1.bias'].data *= state_dict['model.77.im.1.implicit'].data.squeeze()\n",
    "model.state_dict()['model.77.m.2.bias'].data *= state_dict['model.77.im.2.implicit'].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "torch.save(ckpt, 'export/reparam/yolov7-tiny.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f1beb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.0.conv.weight', 'model.0.bn.weight', 'model.0.bn.bias', 'model.0.bn.running_mean', 'model.0.bn.running_var', 'model.0.bn.num_batches_tracked', 'model.1.conv.weight', 'model.1.bn.weight', 'model.1.bn.bias', 'model.1.bn.running_mean', 'model.1.bn.running_var', 'model.1.bn.num_batches_tracked', 'model.2.conv.weight', 'model.2.bn.weight', 'model.2.bn.bias', 'model.2.bn.running_mean', 'model.2.bn.running_var', 'model.2.bn.num_batches_tracked', 'model.3.conv.weight', 'model.3.bn.weight', 'model.3.bn.bias', 'model.3.bn.running_mean', 'model.3.bn.running_var', 'model.3.bn.num_batches_tracked', 'model.4.conv.weight', 'model.4.bn.weight', 'model.4.bn.bias', 'model.4.bn.running_mean', 'model.4.bn.running_var', 'model.4.bn.num_batches_tracked', 'model.5.conv.weight', 'model.5.bn.weight', 'model.5.bn.bias', 'model.5.bn.running_mean', 'model.5.bn.running_var', 'model.5.bn.num_batches_tracked', 'model.7.conv.weight', 'model.7.bn.weight', 'model.7.bn.bias', 'model.7.bn.running_mean', 'model.7.bn.running_var', 'model.7.bn.num_batches_tracked', 'model.9.conv.weight', 'model.9.bn.weight', 'model.9.bn.bias', 'model.9.bn.running_mean', 'model.9.bn.running_var', 'model.9.bn.num_batches_tracked', 'model.10.conv.weight', 'model.10.bn.weight', 'model.10.bn.bias', 'model.10.bn.running_mean', 'model.10.bn.running_var', 'model.10.bn.num_batches_tracked', 'model.11.conv.weight', 'model.11.bn.weight', 'model.11.bn.bias', 'model.11.bn.running_mean', 'model.11.bn.running_var', 'model.11.bn.num_batches_tracked', 'model.12.conv.weight', 'model.12.bn.weight', 'model.12.bn.bias', 'model.12.bn.running_mean', 'model.12.bn.running_var', 'model.12.bn.num_batches_tracked', 'model.14.conv.weight', 'model.14.bn.weight', 'model.14.bn.bias', 'model.14.bn.running_mean', 'model.14.bn.running_var', 'model.14.bn.num_batches_tracked', 'model.16.conv.weight', 'model.16.bn.weight', 'model.16.bn.bias', 'model.16.bn.running_mean', 'model.16.bn.running_var', 'model.16.bn.num_batches_tracked', 'model.17.conv.weight', 'model.17.bn.weight', 'model.17.bn.bias', 'model.17.bn.running_mean', 'model.17.bn.running_var', 'model.17.bn.num_batches_tracked', 'model.18.conv.weight', 'model.18.bn.weight', 'model.18.bn.bias', 'model.18.bn.running_mean', 'model.18.bn.running_var', 'model.18.bn.num_batches_tracked', 'model.19.conv.weight', 'model.19.bn.weight', 'model.19.bn.bias', 'model.19.bn.running_mean', 'model.19.bn.running_var', 'model.19.bn.num_batches_tracked', 'model.21.conv.weight', 'model.21.bn.weight', 'model.21.bn.bias', 'model.21.bn.running_mean', 'model.21.bn.running_var', 'model.21.bn.num_batches_tracked', 'model.23.conv.weight', 'model.23.bn.weight', 'model.23.bn.bias', 'model.23.bn.running_mean', 'model.23.bn.running_var', 'model.23.bn.num_batches_tracked', 'model.24.conv.weight', 'model.24.bn.weight', 'model.24.bn.bias', 'model.24.bn.running_mean', 'model.24.bn.running_var', 'model.24.bn.num_batches_tracked', 'model.25.conv.weight', 'model.25.bn.weight', 'model.25.bn.bias', 'model.25.bn.running_mean', 'model.25.bn.running_var', 'model.25.bn.num_batches_tracked', 'model.26.conv.weight', 'model.26.bn.weight', 'model.26.bn.bias', 'model.26.bn.running_mean', 'model.26.bn.running_var', 'model.26.bn.num_batches_tracked', 'model.28.conv.weight', 'model.28.bn.weight', 'model.28.bn.bias', 'model.28.bn.running_mean', 'model.28.bn.running_var', 'model.28.bn.num_batches_tracked', 'model.29.conv.weight', 'model.29.bn.weight', 'model.29.bn.bias', 'model.29.bn.running_mean', 'model.29.bn.running_var', 'model.29.bn.num_batches_tracked', 'model.30.conv.weight', 'model.30.bn.weight', 'model.30.bn.bias', 'model.30.bn.running_mean', 'model.30.bn.running_var', 'model.30.bn.num_batches_tracked', 'model.35.conv.weight', 'model.35.bn.weight', 'model.35.bn.bias', 'model.35.bn.running_mean', 'model.35.bn.running_var', 'model.35.bn.num_batches_tracked', 'model.37.conv.weight', 'model.37.bn.weight', 'model.37.bn.bias', 'model.37.bn.running_mean', 'model.37.bn.running_var', 'model.37.bn.num_batches_tracked', 'model.38.conv.weight', 'model.38.bn.weight', 'model.38.bn.bias', 'model.38.bn.running_mean', 'model.38.bn.running_var', 'model.38.bn.num_batches_tracked', 'model.40.conv.weight', 'model.40.bn.weight', 'model.40.bn.bias', 'model.40.bn.running_mean', 'model.40.bn.running_var', 'model.40.bn.num_batches_tracked', 'model.42.conv.weight', 'model.42.bn.weight', 'model.42.bn.bias', 'model.42.bn.running_mean', 'model.42.bn.running_var', 'model.42.bn.num_batches_tracked', 'model.43.conv.weight', 'model.43.bn.weight', 'model.43.bn.bias', 'model.43.bn.running_mean', 'model.43.bn.running_var', 'model.43.bn.num_batches_tracked', 'model.44.conv.weight', 'model.44.bn.weight', 'model.44.bn.bias', 'model.44.bn.running_mean', 'model.44.bn.running_var', 'model.44.bn.num_batches_tracked', 'model.45.conv.weight', 'model.45.bn.weight', 'model.45.bn.bias', 'model.45.bn.running_mean', 'model.45.bn.running_var', 'model.45.bn.num_batches_tracked', 'model.47.conv.weight', 'model.47.bn.weight', 'model.47.bn.bias', 'model.47.bn.running_mean', 'model.47.bn.running_var', 'model.47.bn.num_batches_tracked', 'model.48.conv.weight', 'model.48.bn.weight', 'model.48.bn.bias', 'model.48.bn.running_mean', 'model.48.bn.running_var', 'model.48.bn.num_batches_tracked', 'model.50.conv.weight', 'model.50.bn.weight', 'model.50.bn.bias', 'model.50.bn.running_mean', 'model.50.bn.running_var', 'model.50.bn.num_batches_tracked', 'model.52.conv.weight', 'model.52.bn.weight', 'model.52.bn.bias', 'model.52.bn.running_mean', 'model.52.bn.running_var', 'model.52.bn.num_batches_tracked', 'model.53.conv.weight', 'model.53.bn.weight', 'model.53.bn.bias', 'model.53.bn.running_mean', 'model.53.bn.running_var', 'model.53.bn.num_batches_tracked', 'model.54.conv.weight', 'model.54.bn.weight', 'model.54.bn.bias', 'model.54.bn.running_mean', 'model.54.bn.running_var', 'model.54.bn.num_batches_tracked', 'model.55.conv.weight', 'model.55.bn.weight', 'model.55.bn.bias', 'model.55.bn.running_mean', 'model.55.bn.running_var', 'model.55.bn.num_batches_tracked', 'model.57.conv.weight', 'model.57.bn.weight', 'model.57.bn.bias', 'model.57.bn.running_mean', 'model.57.bn.running_var', 'model.57.bn.num_batches_tracked', 'model.58.conv.weight', 'model.58.bn.weight', 'model.58.bn.bias', 'model.58.bn.running_mean', 'model.58.bn.running_var', 'model.58.bn.num_batches_tracked', 'model.60.conv.weight', 'model.60.bn.weight', 'model.60.bn.bias', 'model.60.bn.running_mean', 'model.60.bn.running_var', 'model.60.bn.num_batches_tracked', 'model.61.conv.weight', 'model.61.bn.weight', 'model.61.bn.bias', 'model.61.bn.running_mean', 'model.61.bn.running_var', 'model.61.bn.num_batches_tracked', 'model.62.conv.weight', 'model.62.bn.weight', 'model.62.bn.bias', 'model.62.bn.running_mean', 'model.62.bn.running_var', 'model.62.bn.num_batches_tracked', 'model.63.conv.weight', 'model.63.bn.weight', 'model.63.bn.bias', 'model.63.bn.running_mean', 'model.63.bn.running_var', 'model.63.bn.num_batches_tracked', 'model.65.conv.weight', 'model.65.bn.weight', 'model.65.bn.bias', 'model.65.bn.running_mean', 'model.65.bn.running_var', 'model.65.bn.num_batches_tracked', 'model.66.conv.weight', 'model.66.bn.weight', 'model.66.bn.bias', 'model.66.bn.running_mean', 'model.66.bn.running_var', 'model.66.bn.num_batches_tracked', 'model.68.conv.weight', 'model.68.bn.weight', 'model.68.bn.bias', 'model.68.bn.running_mean', 'model.68.bn.running_var', 'model.68.bn.num_batches_tracked', 'model.69.conv.weight', 'model.69.bn.weight', 'model.69.bn.bias', 'model.69.bn.running_mean', 'model.69.bn.running_var', 'model.69.bn.num_batches_tracked', 'model.70.conv.weight', 'model.70.bn.weight', 'model.70.bn.bias', 'model.70.bn.running_mean', 'model.70.bn.running_var', 'model.70.bn.num_batches_tracked', 'model.71.conv.weight', 'model.71.bn.weight', 'model.71.bn.bias', 'model.71.bn.running_mean', 'model.71.bn.running_var', 'model.71.bn.num_batches_tracked', 'model.73.conv.weight', 'model.73.bn.weight', 'model.73.bn.bias', 'model.73.bn.running_mean', 'model.73.bn.running_var', 'model.73.bn.num_batches_tracked', 'model.74.conv.weight', 'model.74.bn.weight', 'model.74.bn.bias', 'model.74.bn.running_mean', 'model.74.bn.running_var', 'model.74.bn.num_batches_tracked', 'model.75.conv.weight', 'model.75.bn.weight', 'model.75.bn.bias', 'model.75.bn.running_mean', 'model.75.bn.running_var', 'model.75.bn.num_batches_tracked', 'model.76.conv.weight', 'model.76.bn.weight', 'model.76.bn.bias', 'model.76.bn.running_mean', 'model.76.bn.running_var', 'model.76.bn.num_batches_tracked', 'model.77.anchors', 'model.77.anchor_grid', 'model.77.m.0.weight', 'model.77.m.0.bias', 'model.77.m.1.weight', 'model.77.m.1.bias', 'model.77.m.2.weight', 'model.77.m.2.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b396a53",
   "metadata": {},
   "source": [
    "## YOLOv7x reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load('cfg/training/yolov7x_trainig.pt', map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "model = Model('cfg/deploy/yolov7x.yaml', ch=3, nc=80).to(device)\n",
    "\n",
    "with open('cfg/deploy/yolov7x.yaml') as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'][0]) // 2\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "# reparametrized YOLOR\n",
    "for i in range((model.nc+5)*anchors):\n",
    "    model.state_dict()['model.121.m.0.weight'].data[i, :, :, :] *= state_dict['model.121.im.0.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.121.m.1.weight'].data[i, :, :, :] *= state_dict['model.121.im.1.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.121.m.2.weight'].data[i, :, :, :] *= state_dict['model.121.im.2.implicit'].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.121.m.0.bias'].data += state_dict['model.121.m.0.weight'].mul(state_dict['model.121.ia.0.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.121.m.1.bias'].data += state_dict['model.121.m.1.weight'].mul(state_dict['model.121.ia.1.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.121.m.2.bias'].data += state_dict['model.121.m.2.weight'].mul(state_dict['model.121.ia.2.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.121.m.0.bias'].data *= state_dict['model.121.im.0.implicit'].data.squeeze()\n",
    "model.state_dict()['model.121.m.1.bias'].data *= state_dict['model.121.im.1.implicit'].data.squeeze()\n",
    "model.state_dict()['model.121.m.2.bias'].data *= state_dict['model.121.im.2.implicit'].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "torch.save(ckpt, 'cfg/deploy/yolov7x.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9108e",
   "metadata": {},
   "source": [
    "## YOLOv7-W6 reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load('cfg/training/yolov7-w6_trainig.pt', map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "model = Model('cfg/deploy/yolov7-w6.yaml', ch=3, nc=80).to(device)\n",
    "\n",
    "with open('cfg/deploy/yolov7-w6.yaml') as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'][0]) // 2\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "idx = 118\n",
    "idx2 = 122\n",
    "\n",
    "# copy weights of lead head\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data -= model.state_dict()['model.{}.m.0.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data -= model.state_dict()['model.{}.m.1.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data -= model.state_dict()['model.{}.m.2.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data -= model.state_dict()['model.{}.m.3.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data -= model.state_dict()['model.{}.m.0.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data -= model.state_dict()['model.{}.m.1.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data -= model.state_dict()['model.{}.m.2.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data -= model.state_dict()['model.{}.m.3.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.bias'.format(idx2)].data\n",
    "\n",
    "# reparametrized YOLOR\n",
    "for i in range((model.nc+5)*anchors):\n",
    "    model.state_dict()['model.{}.m.0.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.0.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.1.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.1.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.2.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.2.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.3.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.3.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].mul(state_dict['model.{}.ia.0.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].mul(state_dict['model.{}.ia.1.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].mul(state_dict['model.{}.ia.2.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].mul(state_dict['model.{}.ia.3.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data *= state_dict['model.{}.im.0.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data *= state_dict['model.{}.im.1.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data *= state_dict['model.{}.im.2.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data *= state_dict['model.{}.im.3.implicit'.format(idx2)].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "torch.save(ckpt, 'cfg/deploy/yolov7-w6.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f093d43",
   "metadata": {},
   "source": [
    "## YOLOv7-E6 reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load('cfg/training/yolov7-e6.pt', map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "model = Model('cfg/deploy/yolov7-e6.yaml', ch=3, nc=80).to(device)\n",
    "\n",
    "with open('cfg/deploy/yolov7-e6.yaml') as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'][0]) // 2\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "idx = 140\n",
    "idx2 = 144\n",
    "\n",
    "# copy weights of lead head\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data -= model.state_dict()['model.{}.m.0.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data -= model.state_dict()['model.{}.m.1.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data -= model.state_dict()['model.{}.m.2.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data -= model.state_dict()['model.{}.m.3.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data -= model.state_dict()['model.{}.m.0.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data -= model.state_dict()['model.{}.m.1.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data -= model.state_dict()['model.{}.m.2.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data -= model.state_dict()['model.{}.m.3.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.bias'.format(idx2)].data\n",
    "\n",
    "# reparametrized YOLOR\n",
    "for i in range((model.nc+5)*anchors):\n",
    "    model.state_dict()['model.{}.m.0.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.0.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.1.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.1.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.2.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.2.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.3.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.3.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].mul(state_dict['model.{}.ia.0.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].mul(state_dict['model.{}.ia.1.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].mul(state_dict['model.{}.ia.2.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].mul(state_dict['model.{}.ia.3.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data *= state_dict['model.{}.im.0.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data *= state_dict['model.{}.im.1.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data *= state_dict['model.{}.im.2.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data *= state_dict['model.{}.im.3.implicit'.format(idx2)].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "torch.save(ckpt, 'cfg/deploy/yolov7-e6.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bccf89",
   "metadata": {},
   "source": [
    "## YOLOv7-D6 reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5216b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load('cfg/training/yolov7-d6_trainig.pt', map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "model = Model('cfg/deploy/yolov7-d6.yaml', ch=3, nc=80).to(device)\n",
    "\n",
    "with open('cfg/deploy/yolov7-d6.yaml') as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'][0]) // 2\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "idx = 162\n",
    "idx2 = 166\n",
    "\n",
    "# copy weights of lead head\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data -= model.state_dict()['model.{}.m.0.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data -= model.state_dict()['model.{}.m.1.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data -= model.state_dict()['model.{}.m.2.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data -= model.state_dict()['model.{}.m.3.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data -= model.state_dict()['model.{}.m.0.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data -= model.state_dict()['model.{}.m.1.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data -= model.state_dict()['model.{}.m.2.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data -= model.state_dict()['model.{}.m.3.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.bias'.format(idx2)].data\n",
    "\n",
    "# reparametrized YOLOR\n",
    "for i in range((model.nc+5)*anchors):\n",
    "    model.state_dict()['model.{}.m.0.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.0.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.1.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.1.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.2.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.2.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.3.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.3.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].mul(state_dict['model.{}.ia.0.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].mul(state_dict['model.{}.ia.1.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].mul(state_dict['model.{}.ia.2.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].mul(state_dict['model.{}.ia.3.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data *= state_dict['model.{}.im.0.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data *= state_dict['model.{}.im.1.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data *= state_dict['model.{}.im.2.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data *= state_dict['model.{}.im.3.implicit'.format(idx2)].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "torch.save(ckpt, 'cfg/deploy/yolov7-d6.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c273b",
   "metadata": {},
   "source": [
    "## YOLOv7-E6E reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635fd8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load('cfg/training/yolov7-e6e_trainig.pt', map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "model = Model('cfg/deploy/yolov7-e6e.yaml', ch=3, nc=80).to(device)\n",
    "\n",
    "with open('cfg/deploy/yolov7-e6e.yaml') as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'][0]) // 2)\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "idx = 261\n",
    "idx2 = 265\n",
    "\n",
    "# copy weights of lead head\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data -= model.state_dict()['model.{}.m.0.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data -= model.state_dict()['model.{}.m.1.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data -= model.state_dict()['model.{}.m.2.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data -= model.state_dict()['model.{}.m.3.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data -= model.state_dict()['model.{}.m.0.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data -= model.state_dict()['model.{}.m.1.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data -= model.state_dict()['model.{}.m.2.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data -= model.state_dict()['model.{}.m.3.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.bias'.format(idx2)].data\n",
    "\n",
    "# reparametrized YOLOR\n",
    "for i in range((model.nc+5)*anchors):\n",
    "    model.state_dict()['model.{}.m.0.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.0.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.1.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.1.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.2.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.2.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.3.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.3.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].mul(state_dict['model.{}.ia.0.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].mul(state_dict['model.{}.ia.1.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].mul(state_dict['model.{}.ia.2.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].mul(state_dict['model.{}.ia.3.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data *= state_dict['model.{}.im.0.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data *= state_dict['model.{}.im.1.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data *= state_dict['model.{}.im.2.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data *= state_dict['model.{}.im.3.implicit'.format(idx2)].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "torch.save(ckpt, 'cfg/deploy/yolov7-e6e.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a62625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
